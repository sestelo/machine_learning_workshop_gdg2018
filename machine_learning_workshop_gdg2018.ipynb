{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Practice\n",
    "\n",
    "Nora M. Villanueva (nmvillanueva@gradiant.org) & Marta Sestelo (msestelo@gradiant.org)\n",
    "\n",
    "\n",
    "GDG DevFest Galicia 2018\n",
    "\n",
    "Santiago de Compostela, Spain. 17th November 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Machine Learning framework will be introduced by showing both supervised and unsupervised learning methods.  We will describe some of the most well-known and widely used techniques: (1) regression models, (2) classification models, (3) generalized additive models, (4) tree-based models and (5) clustering. We will focus on understanding some mathematical details of these models and how to carry out a practical use of them. We will illustrate these techniques analyzing two different case studies, using to this end a free interactive computing environment, a Jupyter notebook including the R kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "\n",
    "1. [Linear Regression Models](#lm)\n",
    "2. [Generalized Linear Models](#glm)\n",
    "3. [Generalized Additive Models](#gam)\n",
    "4. [Tree-based Method](#trees)\n",
    "    - [Decision trees](#tree)\n",
    "    - [Random Forest](#rf)\n",
    "5. [Model Evaluation](#eval)\n",
    "6. [Clustering](#cluster)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting, it is necessary to load the required packages. Both `ggplot2`, `dplyr` and `readr` are included in the [`tidyverse`](https://www.tidyverse.org/) package collection, so you can load just this package. \n",
    "\n",
    "Note: in the case you use a jupyter notebook you have to load the packages one by one.\n",
    "\n",
    "The previous packages will be used for a very short exploratory data analysis. For modelling, we are going to use the `mgcv`, `rpart` and `randomForest` packages, apart from the functions included in the `base` package. Finally,  for evaluation, we are going to load the `Metrics`, `OptimalCutpoints` and `ROCR` packages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# library(tidyverse)\n",
    "# For EDA\n",
    "library(dplyr) \n",
    "library(ggplot2)\n",
    "library(readr)\n",
    "\n",
    "# For modelling\n",
    "library(mgcv) \n",
    "library(rpart)\n",
    "library(randomForest)\n",
    "\n",
    "# More things...\n",
    "library(rpart.plot)\n",
    "library(Metrics)\n",
    "library(OptimalCutpoints)\n",
    "library(ROCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 8, repr.plot.height = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "This is one of the most used techniques for assesing the relationship between a set of predictors and the response. There are two main reasons because we want to estimate the coefficients of a linear model: inference and prediction.\n",
    "\n",
    "The goal of our first use case is to predict the price per square meter of an apartment in Warsaw (Poland) based on selected features such as construction year, surface, floor, number of rooms and district. It should be noted that four of these variables are continuous while the fifth one is a categorical one. Prices are given in Euro. This dataset is available in the `DALEX` package.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartments <- read_csv(\"https://raw.githubusercontent.com/sestelo/machine_learning_workshop_gdg2018/master/apartments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apartments$district <- as.factor(apartments$district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplot(y = m2.price, x = district, data = apartments, geom = \"boxplot\", fill = district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplot(x = surface, y = m2.price, data = apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- lm(m2.price ~ surface, data = apartments) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qplot(x = surface, y = m2.price, data = apartments, geom = \"smooth\", method = \"lm\") + geom_point()\n",
    "# plot(apartments$surface, apartments$m2.price)\n",
    "# abline(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model <- lm(m2.price ~ ., data = apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(lm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels(apartments$district)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par(mfrow=c(2,3))\n",
    "termplot(lm_model, se = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m3 <- lm(m2.price ~ surface + floor + no.rooms + district, data = apartments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anova(m3, m2) # null model vs full model  test F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, district = \"Srodmiescie\")\n",
    "muhat <- predict(lm_model, newdata = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"glm\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Models\n",
    "\n",
    "`R` makes it very easy to fit a logistic regression model. The function used for this purpose is `glm()` and the fitting process is not so different from the one used in linear regression. \n",
    "\n",
    "We’ll be working on the Titanic dataset. There are different versions of this dataset freely available online.\n",
    "\n",
    "The dataset is a collection (n = 1309) of data about some of the passengers and the goal here is to predict the survival (either 1 if the passenger survived or 0 if they did not) based on some features such as the sex, the age, the fare of the ticket, etc. (both categorical and continuous variables).  Data frame with the following 14 columns:\n",
    "\n",
    "PassengerId: Passenger ID, Survived: Passenger Survival Indicator, Pclass: Passenger Class, Name: Name, Sex: Sex, Age: Age, SibSp: Number of Siblings/Spouses Aboard, Parch: Number of Parents/Children Aboard,Ticket: Ticket Number, Fare: Passenger Fare, Cabin: Cabin, Embarked: Port of Embarkation, Home.dest: Home destination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download.file(\"https://goo.gl/At238b\", \"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic <- read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model <- glm(survived ~ sex + age + fare + sibsp, family = binomial(link = \"logit\"), data = titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(glm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if beta positive, odds ratio > 1: increase prob\n",
    "# if beta negative, odds ratio < 1: deacrease prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp(coef(glm_model)) # from female to male decreases the probability 92%\n",
    "                    # to increase a year decreases the probability 2%\n",
    "                       # to increase 1 euro increases the probability 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will our model tell us about Rose and Jack?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(sex = c(\"female\", \"male\"), age = c(17, 23), fare = c(150, 15), sibsp = c(3, 0))\n",
    "muhat <- predict(glm_model, newdata = df, type = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "muhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gam\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Additive Models\n",
    "\n",
    "\n",
    "Coming back to the `apartments` dataset, can the relationship between the prize of the meter square and each predictor be adequately summarized using a linear equation, or is the relationship more complicated?\n",
    "\n",
    "Now it is time to fit a model using a more flexible structure. For this, we can apply the `gam()` function of the `mgcv` package which apply splines to estimate each of the f functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gam_model <- gam(m2.price ~ s(construction.year) + s(surface) + s(floor) + \n",
    "             s(no.rooms, k = 5) + district, data = apartments)\n",
    "# s() Function used in definition of smooth terms within gam model formulae.\n",
    "# k = the dimension of the basis used to represent the smooth term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(gam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(gam_model, pages = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(gam_model, select = 1, shade = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, district = \"Srodmiescie\")\n",
    "muhat <- predict(gam_model, newdata = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(muhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"trees\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model based-tree\n",
    "\n",
    "We move now to the based-tree methods, particularly, we will focus on decision trees, random forest and gradient boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tree\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Decision tree \n",
    "\n",
    "We start showing how one can apply a decision tree approach. The function `rpart` can run a regression tree if the response variable is numeric, and a classification tree if it is a categorical one. We can see that this technique is a very intuitive and simple approach. Firstly, we carry out the regression analysis taking into account the `apartments` data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model <- rpart(m2.price ~ ., method = \"anova\", data = apartments) # anova is for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.plot(tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, district = \"Srodmiescie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict(tree_model, newdata = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"rf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "In this part, we will explain how apply the random forest technique in practice for regresion and classification. \n",
    "\n",
    "Now, we will create a Random Forest model with default parameters and then we will fine tune the model by changing `mtry` (number of variables randomly sampled at each stage ) and `ntree` (number of trees). By default, number of trees is 500 and number of variables tried at each split is 1 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model <- randomForest(m2.price ~ construction.year + surface + floor + \n",
    "                      no.rooms + district, data = apartments, ntree = 500, mtry = 1)\n",
    "# ntree: number of tree to grow = 1000\n",
    "# mtry:number of variables randomly sample  = 2  (p/3 - regression, sqrt(p) - classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varImpPlot(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- data.frame(m2.price = 200, construction.year = 2000, surface = 70, floor = 3, no.rooms = 2, \n",
    "                 district = \"Srodmiescie\")\n",
    "apartments2 <- rbind(apartments, df)\n",
    "\n",
    "muhat <- predict(rf_model, newdata = apartments2[1001, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "\n",
    "Now, we will split the dataset into train and test set in the ratio 80:20. Firstly, we are going to evaluate the regression model and then the classification ones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression problem\n",
    "\n",
    "For the evaluation, we are going to use 1-Fold CV with the Mean Square Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(30072016)\n",
    "train <- apartments %>% sample_frac(.80)\n",
    "test  <- anti_join(apartments, train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model <- lm(m2.price ~ ., data = train)\n",
    "gam_model <- gam(m2.price ~ s(construction.year) + s(surface) + s(floor) + s(no.rooms, k = 5) + district, data = train)\n",
    "tree_model <- rpart(m2.price ~ ., method = \"anova\", data = train) \n",
    "rf_model <- randomForest(m2.price ~ construction.year + surface \n",
    "                         + floor + no.rooms + district, data = train, ntree = 1000, mtry = 2)\n",
    "\n",
    "muhat_lm <- predict(lm_model, newdata = test)\n",
    "muhat_gam <- predict(gam_model, newdata = test)\n",
    "muhat_tree <- predict(tree_model, newdata = test)\n",
    "muhat_rf <- predict(rf_model, newdata = test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mse_lm <- mean((test$m2.price - muhat_lm)**2))\n",
    "(mse_gam <- mean((test$m2.price - muhat_gam)**2))\n",
    "(mse_tree <- mean((test$m2.price - muhat_tree)**2))\n",
    "(mse_rf <- mean((test$m2.price - muhat_rf)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification problem\n",
    "\n",
    "For the evaluation, we are going to use 1-Fold CV with the Mean Square Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(30072016)\n",
    "titanic2 <- na.omit(titanic[, c(2, 4, 5, 6, 9)])\n",
    "titanic2 <- titanic2  %>% mutate (survived = factor(survived), sex = factor(sex))\n",
    "train <- titanic2 %>% sample_frac(.80)\n",
    "test  <- anti_join(titanic2, train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_model <- glm(survived ~ sex + age + fare + sibsp, family = \"binomial\", data = train)\n",
    "gam_model <- gam(survived ~ sex + s(age) + s(fare) + s(sibsp, k = 7), family = \"binomial\", data = train)\n",
    "tree_model <- rpart(survived ~ sex + age + fare + sibsp, method = \"class\", data = train)\n",
    "rf_model <- randomForest(survived ~ sex + age + fare + sibsp, data = train)\n",
    "\n",
    "muhat_glm <- predict(glm_model, newdata = test, type = \"response\")\n",
    "muhat_gam <- predict(gam_model, newdata = test, type = \"response\")\n",
    "muhat_tree <- predict(tree_model, newdata = test)\n",
    "muhat_rf <- predict(rf_model, newdata = test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For selecting the best model we are going to use the AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(glm_auc <- auc(test$survived, muhat_glm))\n",
    "(gam_auc <- auc(test$survived, muhat_gam))\n",
    "(tree_auc <- auc(test$survived, muhat_tree[, 2]))\n",
    "(rf_auc <- auc(test$survived, as.numeric(muhat_rf)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculating the confusion matrix we need to obtain the best threshold...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux <- data.frame(muhat = muhat_glm, yreal = test$survived)\n",
    "\n",
    "opt <- optimal.cutpoints(X = \"muhat\", status = \"yreal\", tag.healthy = 0, \n",
    "                         methods = \"Youden\", data = aux, pop.prev = NULL, \n",
    "                         control = control.cutpoints(), ci.fit = FALSE, \n",
    "                         conf.level = 0.95, trace = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <-ifelse(muhat_glm >= opt$Youden$Global$optimal.cutoff$cutoff, 1, 0)\n",
    "(confusion_matrix <- table(test$survived, pred))\n",
    "(accuracy <- (sum(diag(confusion_matrix)))/sum(confusion_matrix))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting the ROC curve..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred <- prediction(as.vector(muhat_glm), test$survived)\n",
    "aux <- performance(pred, \"tpr\", \"fpr\")\n",
    "plot(aux)\n",
    "mtext(paste(\"AUC =\",round(glm_auc, 4)), side = 1, line =-2, col =\"blue\" ,cex=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cluster\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(iris)\n",
    "x <- iris[,-5]\n",
    "y <- iris$Species\n",
    "cl3 <- kmeans(x[, c(1,3)], centers = 3, nstart = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl3$tot.withinss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris  %>% \n",
    "    select(Sepal.Length, Petal.Length)  %>% \n",
    "    qplot(y = Sepal.Length, x = Petal.Length, data = ., geom = \"point\", colour = factor(cl3$cluster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/><br/><br/><br/><div style=\"text-align: right\">Material mainly based on the book **[The Elements of Statistical Learning: Data Mining, Inference, and Prediction](https://web.stanford.edu/~hastie/ElemStatLearn/)** (Hastie, Tibshirani and Friedman, 2009).</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
